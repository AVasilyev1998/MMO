{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-BtM2SqM3jz"
   },
   "source": [
    "# Лабораторная работа №6\n",
    "## Васильев А.Р. ИУ5-24М\n",
    "\n",
    "### Цель лабораторной работы: изучение методов классификации текстов.\n",
    "\n",
    "### Требования к отчету:\n",
    "#### Отчет по лабораторной работе должен содержать:\n",
    "\n",
    "- титульный лист;\n",
    "- описание задания;\n",
    "- текст программы;\n",
    "- экранные формы с примерами выполнения программы.\n",
    "\n",
    "#### Задание - для произвольного набора данных, предназначенного для классификации текстов, решите задачу классификации текста двумя способами:\n",
    "\n",
    "- Способ 1. На основе CountVectorizer или TfidfVectorizer.\n",
    "- Способ 2. На основе моделей word2vec или Glove или fastText.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PB7IF6k9M3PU",
    "outputId": "a9586f2e-fd1c-4133-b1c0-e76824e6980d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "nltk.download('punkt')\n",
    "from nltk import tokenize\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUIt4hXaM2yP"
   },
   "source": [
    "## Будем использовать датасет 20 newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "N4izXsLUIPKJ"
   },
   "outputs": [],
   "source": [
    "categories = [\"rec.autos\", \"rec.sport.hockey\", \"sci.crypt\", \"sci.med\", \"talk.religion.misc\"]\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eVfbL7XzKSvb"
   },
   "outputs": [],
   "source": [
    "unique, frequency = np.unique(newsgroups_train.target, \n",
    "                              return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NU4064dJLhI3",
    "outputId": "7f3b28a4-4ed4-4ad4-d2ef-cd48d815bba2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value: 0, count: 594\n",
      "value: 1, count: 600\n",
      "value: 2, count: 595\n",
      "value: 3, count: 594\n",
      "value: 4, count: 377\n"
     ]
    }
   ],
   "source": [
    "for l, f in zip(unique, frequency):\n",
    "  print(f'value: {l}, count: {f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oYLE19elMQZz",
    "outputId": "55724c49-8dd4-4e68-c805-bf496ca1fdc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizers NLTK have\n",
      "BlanklineTokenizer\n",
      "LineTokenizer\n",
      "MWETokenizer\n",
      "PunktSentenceTokenizer\n",
      "RegexpTokenizer\n",
      "ReppTokenizer\n",
      "SExprTokenizer\n",
      "SpaceTokenizer\n",
      "StanfordSegmenter\n",
      "TabTokenizer\n",
      "TextTilingTokenizer\n",
      "ToktokTokenizer\n",
      "TreebankWordTokenizer\n",
      "TweetTokenizer\n",
      "WhitespaceTokenizer\n",
      "WordPunctTokenizer\n"
     ]
    }
   ],
   "source": [
    "print('Tokenizers NLTK have')\n",
    "for i in dir(tokenize)[:16]:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nF7eplbYNT1E"
   },
   "source": [
    "## Подготовка текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MELpilnoVsAv",
    "outputId": "b62ce27d-2769-4622-a57c-c593fc3e2049"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "nltk.download('stopwords')\n",
    "stopwords_eng = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LirG_wtMNxBh"
   },
   "outputs": [],
   "source": [
    "def prepare(t):\n",
    "  # t = ' '.join([i.strip().lower() for i in t.split(' ')])\n",
    "  t = re.sub(r'[^a-zA-Z0-9 \\n]', '', t)\n",
    "  t = re.sub('\\s+', ' ', t)\n",
    "  t = ' '.join([token.lemma_.lower() for token in nlp(t) if token not in stopwords_eng])\n",
    "  return t\n",
    "\n",
    "texts = newsgroups_train.data\n",
    "\n",
    "texts_array = []\n",
    "\n",
    "for text in texts:\n",
    "  prepared_text = prepare(text)\n",
    "  texts_array.append(prepared_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lL6uVEv4P0-D",
    "outputId": "5a6f549b-3b83-4674-8335-8e0156f6731d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2760,\n",
       " 'from amolitormoinknmsuedu andrew molitor subject what the clipper naysayer sound like to -pron- organization department of mathematical sciences lines 55 distribution na nntppostinghost moinknmsuedu originator amolitormoinknmsuedu the follow be available in some ftp archive somewhere -pron- insert -pron- comment liberally throughout this demonic memo of big brotherdom white house announcement on screw thread standards this be to announce that the american national standards institute or whatever -pron- be have be give the authority to define standard dimension for screw thread look this be clearly the first step toward outlaw -pron- own screw thread specification if this madness be not fight tooth and nail every step of the way -pron- will be a crime to use screw thread other than those -pron- fearless leader so graciously define for -pron- the purpose of this be to permit industry to draw upon a standard pool of specification and designation to ensure interoperability of various thread object across vendor rubbish -pron- say ansi standard screw thread will have subtle weakness allow -pron- agent to disassemble -pron- automobile more easily cause -pron- muffler to fall off at inoppurtune moment questions and answers on the ansi screw thread standard q will the screw thread define by ansi be as good as other screw thread design available elsewhere a yes hah trust -pron- q will -pron- be able to use -pron- own screw thread if -pron- desire a of course but this will make -pron- thread object unlikely to interoperate correctly with other within the industry see see this be the first step -pron- be clear -pron- must band together write -pron- congressman use pretty good screw thread not this devilinspire ansi trash protect -pron- constitutional right to use whatever screw thread -pron- desire guerilla screw thread activism must become the order of the day boycott gm and build -pron- own car use screw from stz screw thread associates screw -pron- bill clinton -pron- and -pron- totalitarianist thug amolitornmsuedu finger for pgst personal screw thread pitch or screw thread see the screw thread server must be free')"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts_array), texts_array[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jA7_F7gqhLmd"
   },
   "outputs": [],
   "source": [
    "test_texts_arr = []\n",
    "\n",
    "test_texts = newsgroups_test.data\n",
    "\n",
    "for text in test_texts:\n",
    "  prepared_text = prepare(text)\n",
    "  test_texts_arr.append(prepared_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iw6he3I2bX6r"
   },
   "source": [
    "## Способ 1 На основе CountVectorizer и TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6wbzc3wQbcK9"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WPbEe60PbjOl"
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "train_feature_matrix_tfidf = tfidf_vectorizer.fit_transform(texts_array)\n",
    "test_feature_matrix__tfidf = tfidf_vectorizer.transform(test_texts_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yS_7RjpainYg"
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "train_feature_matrix_count = count_vectorizer.fit_transform(texts_array)\n",
    "test_feature_matrix_count = count_vectorizer.transform(test_texts_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "9_77d2qjb4BE"
   },
   "outputs": [],
   "source": [
    "target_values_train = newsgroups_train.target\n",
    "target_values_test = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QrD0YMGi_6m"
   },
   "source": [
    "knn with count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mgr-kLV-i_gU",
    "outputId": "c26e1d41-7477-4e9f-92ec-6150b1d82566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ....................... n_neighbors=2, score=0.844, total=   0.2s\n",
      "[CV] n_neighbors=2 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... n_neighbors=2, score=0.837, total=   0.2s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ....................... n_neighbors=2, score=0.861, total=   0.2s\n",
      "[CV] n_neighbors=2 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... n_neighbors=2, score=0.833, total=   0.2s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ....................... n_neighbors=2, score=0.842, total=   0.2s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.862, total=   0.2s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.858, total=   0.2s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.863, total=   0.2s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.849, total=   0.2s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.858, total=   0.2s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.864, total=   0.2s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.858, total=   0.2s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.867, total=   0.2s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.854, total=   0.2s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.869, total=   0.2s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ....................... n_neighbors=7, score=0.865, total=   0.2s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ....................... n_neighbors=7, score=0.863, total=   0.2s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ....................... n_neighbors=7, score=0.871, total=   0.2s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ....................... n_neighbors=7, score=0.840, total=   0.2s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ....................... n_neighbors=7, score=0.873, total=   0.2s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ....................... n_neighbors=9, score=0.861, total=   0.2s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ....................... n_neighbors=9, score=0.862, total=   0.2s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ....................... n_neighbors=9, score=0.874, total=   0.2s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ....................... n_neighbors=9, score=0.838, total=   0.2s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ....................... n_neighbors=9, score=0.871, total=   0.2s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ...................... n_neighbors=11, score=0.861, total=   0.2s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ...................... n_neighbors=11, score=0.857, total=   0.2s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ...................... n_neighbors=11, score=0.872, total=   0.2s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ...................... n_neighbors=11, score=0.841, total=   0.2s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ...................... n_neighbors=11, score=0.870, total=   0.2s\n",
      "best param of n_neighbors 5\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.71      0.49       396\n",
      "           1       0.64      0.55      0.59       399\n",
      "           2       0.63      0.53      0.58       396\n",
      "           3       0.53      0.36      0.43       396\n",
      "           4       0.57      0.35      0.44       251\n",
      "\n",
      "    accuracy                           0.51      1838\n",
      "   macro avg       0.55      0.50      0.51      1838\n",
      "weighted avg       0.55      0.51      0.51      1838\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn_count = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "parameters = {'n_neighbors': [2, 3, 5, 7, 9, 11]}\n",
    "\n",
    "knn_count_grid = GridSearchCV(knn_count, parameters, scoring='roc_auc_ovr_weighted',\n",
    "                              verbose=4, cv=5)\n",
    "\n",
    "knn_count_grid.fit(train_feature_matrix_count, target_values_train)\n",
    "\n",
    "# print(pd.DataFrame(knn_count_grid.cv_results_))\n",
    "print('best param of n_neighbors', knn_count_grid.best_params_['n_neighbors'])\n",
    "best_knn_count = KNeighborsClassifier(n_neighbors=knn_count_grid.best_params_['n_neighbors'])\n",
    "print(best_knn_count)\n",
    "best_knn_count.fit(train_feature_matrix_count, target_values_train)\n",
    "best_knn_pred_count = best_knn_count.predict(test_feature_matrix_count)\n",
    "\n",
    "print(classification_report(target_values_test, pred_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zZAqSsvjEx9"
   },
   "source": [
    "knn with tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMIWg2kOh4KU",
    "outputId": "e9d1d57f-b5f1-4291-e619-e0da85f9d325"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ....................... n_neighbors=2, score=0.844, total=   0.2s\n",
      "[CV] n_neighbors=2 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... n_neighbors=2, score=0.837, total=   0.2s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ....................... n_neighbors=2, score=0.861, total=   0.2s\n",
      "[CV] n_neighbors=2 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... n_neighbors=2, score=0.833, total=   0.2s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ....................... n_neighbors=2, score=0.842, total=   0.2s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.862, total=   0.2s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.858, total=   0.2s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.863, total=   0.2s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.849, total=   0.2s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.858, total=   0.2s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.864, total=   0.2s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.858, total=   0.2s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.867, total=   0.2s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.854, total=   0.2s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.869, total=   0.2s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ....................... n_neighbors=7, score=0.865, total=   0.2s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ....................... n_neighbors=7, score=0.863, total=   0.2s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ....................... n_neighbors=7, score=0.871, total=   0.2s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ....................... n_neighbors=7, score=0.840, total=   0.2s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ....................... n_neighbors=7, score=0.873, total=   0.2s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ....................... n_neighbors=9, score=0.861, total=   0.2s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ....................... n_neighbors=9, score=0.862, total=   0.2s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ....................... n_neighbors=9, score=0.874, total=   0.2s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ....................... n_neighbors=9, score=0.838, total=   0.2s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ....................... n_neighbors=9, score=0.871, total=   0.2s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ...................... n_neighbors=11, score=0.861, total=   0.2s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ...................... n_neighbors=11, score=0.857, total=   0.2s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ...................... n_neighbors=11, score=0.872, total=   0.2s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ...................... n_neighbors=11, score=0.841, total=   0.2s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ...................... n_neighbors=11, score=0.870, total=   0.2s\n",
      "best param of n_neighbors 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       396\n",
      "           1       0.97      0.89      0.93       399\n",
      "           2       0.83      0.88      0.86       396\n",
      "           3       0.95      0.64      0.76       396\n",
      "           4       0.57      0.87      0.69       251\n",
      "\n",
      "    accuracy                           0.84      1838\n",
      "   macro avg       0.85      0.84      0.83      1838\n",
      "weighted avg       0.87      0.84      0.84      1838\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_tfidf = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "parameters = {'n_neighbors': [2, 3, 5, 7, 9, 11]}\n",
    "\n",
    "knn_tfidf_grid = GridSearchCV(knn_tfidf, parameters,\n",
    "                              scoring='roc_auc_ovr_weighted',\n",
    "                              verbose=4, cv=5)\n",
    "\n",
    "knn_tfidf_grid.fit(train_feature_matrix_count, target_values_train)\n",
    "\n",
    "print('best param of n_neighbors', knn_count_grid.best_params_['n_neighbors'])\n",
    "best_knn_tfidf = KNeighborsClassifier(n_neighbors=knn_count_grid.best_params_['n_neighbors'])\n",
    "\n",
    "best_knn_tfidf.fit(train_feature_matrix_tfidf, target_values_train)\n",
    "best_pred_knn = best_knn_tfidf.predict(test_feature_matrix__tfidf)\n",
    "\n",
    "print(classification_report(target_values_test, best_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPXe4VJCjmWC"
   },
   "source": [
    "## Способ 2 На основе моделей word2vec или Glove или fastText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3AVA47CSiKnB"
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader\n",
    "# gensim.downloader.info()\n",
    "# glove_vectors = gensim.downloader.load('glove-twitter-25')\n",
    "glove_vectors = gensim.downloader.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WfxUL2zDVEez"
   },
   "outputs": [],
   "source": [
    "class GloveTokenizer:\n",
    "  def __init__(self, glove_tokenizer):\n",
    "    self.glove = glove_tokenizer\n",
    "    self.token_length = 800\n",
    "    self.embedding_size = 50\n",
    "\n",
    "  def __getitem__(self, word):\n",
    "    try:\n",
    "      vector = glove_vectors.get_vector(word).reshape(1, self.embedding_size)\n",
    "    except KeyError as e:\n",
    "      vector = np.zeros((1, self.embedding_size))\n",
    "    return vector\n",
    "\n",
    "\n",
    "  def __padd(self, sentence):\n",
    "    padded_sentence = np.zeros((self.token_length, self.embedding_size))\n",
    "    for i, token in enumerate(sentence):\n",
    "        padded_sentence[i] = token\n",
    "    return padded_sentence\n",
    "  \n",
    "  def tokenize(self, sentence):\n",
    "    encoded_sentence = []\n",
    "    sentence = sentence.strip(' ').split(' ')\n",
    "    for i in sentence:\n",
    "      token = self.__getitem__(i)\n",
    "      encoded_sentence.append(token)    \n",
    "    return np.array(self.__padd(encoded_sentence), dtype=np.float16)\n",
    "\n",
    "tokenizer = GloveTokenizer(glove_vectors)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yPdVpUtNxMxp",
    "outputId": "68506a31-b474-450a-f9ee-c1237459b182"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 index 800 is out of bounds for axis 0 with size 800\n",
      "58 index 800 is out of bounds for axis 0 with size 800\n",
      "93 index 800 is out of bounds for axis 0 with size 800\n",
      "112 index 800 is out of bounds for axis 0 with size 800\n",
      "147 index 800 is out of bounds for axis 0 with size 800\n",
      "159 index 800 is out of bounds for axis 0 with size 800\n",
      "214 index 800 is out of bounds for axis 0 with size 800\n",
      "215 index 800 is out of bounds for axis 0 with size 800\n",
      "217 index 800 is out of bounds for axis 0 with size 800\n",
      "222 index 800 is out of bounds for axis 0 with size 800\n",
      "265 index 800 is out of bounds for axis 0 with size 800\n",
      "268 index 800 is out of bounds for axis 0 with size 800\n",
      "281 index 800 is out of bounds for axis 0 with size 800\n",
      "336 index 800 is out of bounds for axis 0 with size 800\n",
      "361 index 800 is out of bounds for axis 0 with size 800\n",
      "395 index 800 is out of bounds for axis 0 with size 800\n",
      "412 index 800 is out of bounds for axis 0 with size 800\n",
      "416 index 800 is out of bounds for axis 0 with size 800\n",
      "424 index 800 is out of bounds for axis 0 with size 800\n",
      "462 index 800 is out of bounds for axis 0 with size 800\n",
      "468 index 800 is out of bounds for axis 0 with size 800\n",
      "480 index 800 is out of bounds for axis 0 with size 800\n",
      "568 index 800 is out of bounds for axis 0 with size 800\n",
      "574 index 800 is out of bounds for axis 0 with size 800\n",
      "585 index 800 is out of bounds for axis 0 with size 800\n",
      "587 index 800 is out of bounds for axis 0 with size 800\n",
      "588 index 800 is out of bounds for axis 0 with size 800\n",
      "591 index 800 is out of bounds for axis 0 with size 800\n",
      "680 index 800 is out of bounds for axis 0 with size 800\n",
      "696 index 800 is out of bounds for axis 0 with size 800\n",
      "708 index 800 is out of bounds for axis 0 with size 800\n",
      "714 index 800 is out of bounds for axis 0 with size 800\n",
      "715 index 800 is out of bounds for axis 0 with size 800\n",
      "733 index 800 is out of bounds for axis 0 with size 800\n",
      "734 index 800 is out of bounds for axis 0 with size 800\n",
      "743 index 800 is out of bounds for axis 0 with size 800\n",
      "753 index 800 is out of bounds for axis 0 with size 800\n",
      "816 index 800 is out of bounds for axis 0 with size 800\n",
      "901 index 800 is out of bounds for axis 0 with size 800\n",
      "911 index 800 is out of bounds for axis 0 with size 800\n",
      "962 index 800 is out of bounds for axis 0 with size 800\n",
      "965 index 800 is out of bounds for axis 0 with size 800\n",
      "1015 index 800 is out of bounds for axis 0 with size 800\n",
      "1022 index 800 is out of bounds for axis 0 with size 800\n",
      "1112 index 800 is out of bounds for axis 0 with size 800\n",
      "1116 index 800 is out of bounds for axis 0 with size 800\n",
      "1155 index 800 is out of bounds for axis 0 with size 800\n",
      "1167 index 800 is out of bounds for axis 0 with size 800\n",
      "1170 index 800 is out of bounds for axis 0 with size 800\n",
      "1173 index 800 is out of bounds for axis 0 with size 800\n",
      "1181 index 800 is out of bounds for axis 0 with size 800\n",
      "1265 index 800 is out of bounds for axis 0 with size 800\n",
      "1269 index 800 is out of bounds for axis 0 with size 800\n",
      "1292 index 800 is out of bounds for axis 0 with size 800\n",
      "1294 index 800 is out of bounds for axis 0 with size 800\n",
      "1357 index 800 is out of bounds for axis 0 with size 800\n",
      "1372 index 800 is out of bounds for axis 0 with size 800\n",
      "1398 index 800 is out of bounds for axis 0 with size 800\n",
      "1412 index 800 is out of bounds for axis 0 with size 800\n",
      "1413 index 800 is out of bounds for axis 0 with size 800\n",
      "1422 index 800 is out of bounds for axis 0 with size 800\n",
      "1426 index 800 is out of bounds for axis 0 with size 800\n",
      "1429 index 800 is out of bounds for axis 0 with size 800\n",
      "1442 index 800 is out of bounds for axis 0 with size 800\n",
      "1462 index 800 is out of bounds for axis 0 with size 800\n",
      "1481 index 800 is out of bounds for axis 0 with size 800\n",
      "1501 index 800 is out of bounds for axis 0 with size 800\n",
      "1527 index 800 is out of bounds for axis 0 with size 800\n",
      "1551 index 800 is out of bounds for axis 0 with size 800\n",
      "1584 index 800 is out of bounds for axis 0 with size 800\n",
      "1586 index 800 is out of bounds for axis 0 with size 800\n",
      "1592 index 800 is out of bounds for axis 0 with size 800\n",
      "1605 index 800 is out of bounds for axis 0 with size 800\n",
      "1620 index 800 is out of bounds for axis 0 with size 800\n",
      "1625 index 800 is out of bounds for axis 0 with size 800\n",
      "1672 index 800 is out of bounds for axis 0 with size 800\n",
      "1728 index 800 is out of bounds for axis 0 with size 800\n",
      "1766 index 800 is out of bounds for axis 0 with size 800\n",
      "1781 index 800 is out of bounds for axis 0 with size 800\n",
      "1804 index 800 is out of bounds for axis 0 with size 800\n",
      "1811 index 800 is out of bounds for axis 0 with size 800\n",
      "1812 index 800 is out of bounds for axis 0 with size 800\n",
      "1819 index 800 is out of bounds for axis 0 with size 800\n",
      "1825 index 800 is out of bounds for axis 0 with size 800\n",
      "1832 index 800 is out of bounds for axis 0 with size 800\n",
      "1854 index 800 is out of bounds for axis 0 with size 800\n",
      "1883 index 800 is out of bounds for axis 0 with size 800\n",
      "1891 index 800 is out of bounds for axis 0 with size 800\n",
      "1908 index 800 is out of bounds for axis 0 with size 800\n",
      "1924 index 800 is out of bounds for axis 0 with size 800\n",
      "1958 index 800 is out of bounds for axis 0 with size 800\n",
      "2005 index 800 is out of bounds for axis 0 with size 800\n",
      "2061 index 800 is out of bounds for axis 0 with size 800\n",
      "2086 index 800 is out of bounds for axis 0 with size 800\n",
      "2105 index 800 is out of bounds for axis 0 with size 800\n",
      "2138 index 800 is out of bounds for axis 0 with size 800\n",
      "2149 index 800 is out of bounds for axis 0 with size 800\n",
      "2167 index 800 is out of bounds for axis 0 with size 800\n",
      "2175 index 800 is out of bounds for axis 0 with size 800\n",
      "2180 index 800 is out of bounds for axis 0 with size 800\n",
      "2220 index 800 is out of bounds for axis 0 with size 800\n",
      "2243 index 800 is out of bounds for axis 0 with size 800\n",
      "2260 index 800 is out of bounds for axis 0 with size 800\n",
      "2262 index 800 is out of bounds for axis 0 with size 800\n",
      "2304 index 800 is out of bounds for axis 0 with size 800\n",
      "2328 index 800 is out of bounds for axis 0 with size 800\n",
      "2356 index 800 is out of bounds for axis 0 with size 800\n",
      "2373 index 800 is out of bounds for axis 0 with size 800\n",
      "2391 index 800 is out of bounds for axis 0 with size 800\n",
      "2419 index 800 is out of bounds for axis 0 with size 800\n",
      "2428 index 800 is out of bounds for axis 0 with size 800\n",
      "2462 index 800 is out of bounds for axis 0 with size 800\n",
      "2466 index 800 is out of bounds for axis 0 with size 800\n",
      "2469 index 800 is out of bounds for axis 0 with size 800\n",
      "2487 index 800 is out of bounds for axis 0 with size 800\n",
      "2500 index 800 is out of bounds for axis 0 with size 800\n",
      "2517 index 800 is out of bounds for axis 0 with size 800\n",
      "2559 index 800 is out of bounds for axis 0 with size 800\n",
      "2603 index 800 is out of bounds for axis 0 with size 800\n",
      "2616 index 800 is out of bounds for axis 0 with size 800\n",
      "2628 index 800 is out of bounds for axis 0 with size 800\n",
      "2652 index 800 is out of bounds for axis 0 with size 800\n",
      "2669 index 800 is out of bounds for axis 0 with size 800\n",
      "2678 index 800 is out of bounds for axis 0 with size 800\n",
      "2683 index 800 is out of bounds for axis 0 with size 800\n",
      "2743 index 800 is out of bounds for axis 0 with size 800\n",
      "2754 index 800 is out of bounds for axis 0 with size 800\n",
      "(2633, 800, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2633, 40000)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare(t):\n",
    "  # t = ' '.join([i.strip().lower() for i in t.split(' ')])\n",
    "  t = re.sub(r'[^a-zA-Z0-9 ]', '', t)\n",
    "  t = re.sub('\\s+', ' ', t)\n",
    "  lemmas = [token.lemma_.lower() for token in nlp(t) if token not in stopwords_eng]\n",
    "  t = ' '.join(lemmas)\n",
    "  vectors = tokenizer.tokenize(t)\n",
    "  return vectors, len(lemmas)\n",
    "\n",
    "vectors_array_train = []\n",
    "labels_train = []\n",
    "\n",
    "for enum, text, label in zip(range(len(newsgroups_train.data)), newsgroups_train.data, newsgroups_train.target):\n",
    "  try:\n",
    "    vector, length = prepare(text)\n",
    "    # print(vector, vector.shape)\n",
    "    vectors_array_train.append(vector)\n",
    "    labels_train.append(label)\n",
    "  except IndexError as e:\n",
    "    print(enum, e)\n",
    "    continue\n",
    "\n",
    "\n",
    "vectors_array_train = np.array(vectors_array_train)\n",
    "print(vectors_array_train.shape)\n",
    "train_data = vectors_array_train.reshape((-1, vectors_array_train.shape[1]*vectors_array_train.shape[2]))\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KVZdcUn9YB0b",
    "outputId": "f3ae3565-a104-4717-9061-0faf692c3950"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 index 800 is out of bounds for axis 0 with size 800\n",
      "76 index 800 is out of bounds for axis 0 with size 800\n",
      "124 index 800 is out of bounds for axis 0 with size 800\n",
      "137 index 800 is out of bounds for axis 0 with size 800\n",
      "292 index 800 is out of bounds for axis 0 with size 800\n",
      "298 index 800 is out of bounds for axis 0 with size 800\n",
      "350 index 800 is out of bounds for axis 0 with size 800\n",
      "432 index 800 is out of bounds for axis 0 with size 800\n",
      "435 index 800 is out of bounds for axis 0 with size 800\n",
      "476 index 800 is out of bounds for axis 0 with size 800\n",
      "484 index 800 is out of bounds for axis 0 with size 800\n",
      "525 index 800 is out of bounds for axis 0 with size 800\n",
      "558 index 800 is out of bounds for axis 0 with size 800\n",
      "618 index 800 is out of bounds for axis 0 with size 800\n",
      "680 index 800 is out of bounds for axis 0 with size 800\n",
      "710 index 800 is out of bounds for axis 0 with size 800\n",
      "720 index 800 is out of bounds for axis 0 with size 800\n",
      "778 index 800 is out of bounds for axis 0 with size 800\n",
      "780 index 800 is out of bounds for axis 0 with size 800\n",
      "802 index 800 is out of bounds for axis 0 with size 800\n",
      "819 index 800 is out of bounds for axis 0 with size 800\n",
      "825 index 800 is out of bounds for axis 0 with size 800\n",
      "836 index 800 is out of bounds for axis 0 with size 800\n",
      "862 index 800 is out of bounds for axis 0 with size 800\n",
      "882 index 800 is out of bounds for axis 0 with size 800\n",
      "956 index 800 is out of bounds for axis 0 with size 800\n",
      "960 index 800 is out of bounds for axis 0 with size 800\n",
      "989 index 800 is out of bounds for axis 0 with size 800\n",
      "1064 index 800 is out of bounds for axis 0 with size 800\n",
      "1101 index 800 is out of bounds for axis 0 with size 800\n",
      "1108 index 800 is out of bounds for axis 0 with size 800\n",
      "1152 index 800 is out of bounds for axis 0 with size 800\n",
      "1187 index 800 is out of bounds for axis 0 with size 800\n",
      "1193 index 800 is out of bounds for axis 0 with size 800\n",
      "1293 index 800 is out of bounds for axis 0 with size 800\n",
      "1313 index 800 is out of bounds for axis 0 with size 800\n",
      "1386 index 800 is out of bounds for axis 0 with size 800\n",
      "1443 index 800 is out of bounds for axis 0 with size 800\n",
      "1455 index 800 is out of bounds for axis 0 with size 800\n",
      "1463 index 800 is out of bounds for axis 0 with size 800\n",
      "1477 index 800 is out of bounds for axis 0 with size 800\n",
      "1482 index 800 is out of bounds for axis 0 with size 800\n",
      "1529 index 800 is out of bounds for axis 0 with size 800\n",
      "1552 index 800 is out of bounds for axis 0 with size 800\n",
      "1560 index 800 is out of bounds for axis 0 with size 800\n",
      "1561 index 800 is out of bounds for axis 0 with size 800\n",
      "1629 index 800 is out of bounds for axis 0 with size 800\n",
      "1631 index 800 is out of bounds for axis 0 with size 800\n",
      "1639 index 800 is out of bounds for axis 0 with size 800\n",
      "1664 index 800 is out of bounds for axis 0 with size 800\n",
      "1709 index 800 is out of bounds for axis 0 with size 800\n",
      "1717 index 800 is out of bounds for axis 0 with size 800\n",
      "1770 index 800 is out of bounds for axis 0 with size 800\n",
      "1837 index 800 is out of bounds for axis 0 with size 800\n"
     ]
    }
   ],
   "source": [
    "vectors_array_test = []\n",
    "labels_test= []\n",
    "\n",
    "for enum, text, label in zip(range(len(newsgroups_test.data)), newsgroups_test.data, newsgroups_test.target):\n",
    "  try:\n",
    "    vector, length = prepare(text)\n",
    "    vectors_array_test.append(vector)\n",
    "    labels_test.append(label)\n",
    "  except IndexError as e:\n",
    "    print(enum, e)\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E-U8YXNCh9ar",
    "outputId": "c48b60bf-f730-4af6-fbf3-0715ab68e75e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1784, 40000)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_array_test = np.array(vectors_array_test)\n",
    "test_data = vectors_array_test.reshape((-1, vectors_array_test.shape[1]*vectors_array_test.shape[2]))\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "67smIprhlUvz",
    "outputId": "babb7e03-f3e5-4cab-f61a-d7ca995d1dc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 22.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param of n_neighbors 9\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8b00f2d61c86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_pred_glove_knn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "glove_knn_clf = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors': [2, 3, 5, 7, 9]}\n",
    "\n",
    "glove_clf_grid = GridSearchCV(glove_knn_clf, parameters, verbose=4, cv=3,\n",
    "                            scoring='roc_auc_ovr_weighted', n_jobs=-1)\n",
    "\n",
    "\n",
    "glove_clf_grid.fit(train_data, labels_train)\n",
    "\n",
    "print('best param of n_neighbors', glove_clf_grid.best_params_['n_neighbors'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xqf9YL1LyQhD",
    "outputId": "de4c79ea-a468-457b-9590-adc9c3afadad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.83      0.42       169\n",
      "           1       0.49      0.23      0.32       171\n",
      "           2       0.51      0.19      0.28       180\n",
      "           3       0.42      0.17      0.24       164\n",
      "           4       0.46      0.32      0.38       116\n",
      "\n",
      "    accuracy                           0.35       800\n",
      "   macro avg       0.43      0.35      0.33       800\n",
      "weighted avg       0.43      0.35      0.32       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "best_glove_knn = KNeighborsClassifier(n_neighbors=glove_clf_grid.best_params_['n_neighbors'])\n",
    "\n",
    "best_glove_knn.fit(train_data, labels_train)\n",
    "\n",
    "best_pred_glove_knn = best_glove_knn.predict(test_data[:800])\n",
    "\n",
    "\n",
    "print(classification_report(labels_test[:800], best_pred_glove_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fYIc5wM9Ya45"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MMO_lab_6.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
